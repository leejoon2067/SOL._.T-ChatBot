import streamlit as st
from langchain_core.messages import ChatMessage
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import os

from utils_.utils import print_messages
from utils_.chain_v1 import get_response
# from utils_.chain_ver2 import get_response2
# from utils_.chain_ver3 import get_response3

st.set_page_config(
    page_title = "ì—°ì•  ì†”ë£¨ì…˜ ì±—ë´‡ 'Sol-T'",
    page_icon = "ğŸ’"
)
st.title("ë‹¹ì‹ ì˜ ì—°ì•  ì†”ë£¨ì…˜ ì±—ë´‡ SOL._.TğŸ’")
st.divider()

st.markdown("##### **ğŸ˜ ì í‹°**ì—ê²Œ ë‹¹ì‹ ì˜ ê³ ë¯¼ì„ í„¸ì–´ë³´ì•„ìš”!!!")

# API key ì„¤ì •
load_dotenv()
os.environ.get("OPENAI_API_KEY")

if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥í•´ì£¼ëŠ” í•¨ìˆ˜. 
print_messages()

if user_input := st.chat_input("ì–´ë–¤ ê²ƒì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"):
    # ì‚¬ìš©ì ì…ë ¥ 
    st.chat_message("user").write(f"{user_input}")
    st.session_state["messages"].append(ChatMessage(role = "user", content = user_input))

    # LLM ë‹µë³€ ìƒì„± ì˜ˆì‹œ : ver1 - get_response1
    response = get_response(user_input)
    msg = response

    # LLM ë‹µë³€ ìƒì„± ì˜ˆì‹œ : ver2 - get_response2
    # response = get_response(user_input)
    # msg2 = response

    # LLM ë‹µë³€ ìƒì„± ì˜ˆì‹œ : ver3 - get response3
    # response = get_response3(user_input)
    # msg3 = response

    # AI ë‹µë³€    
    with st.chat_message("assistant"):
        st.write(msg)
        st.session_state["messages"].append(ChatMessage(role = "assistant", content = msg))